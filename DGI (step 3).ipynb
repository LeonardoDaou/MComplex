{"cells":[{"cell_type":"code","execution_count":5,"id":"vslGGf-h8xFe","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4690,"status":"ok","timestamp":1726994768739,"user":{"displayName":"Leonardo Daou","userId":"14703396650585608715"},"user_tz":-180},"id":"vslGGf-h8xFe","outputId":"4f6003c3-3a73-4855-cfbb-801987a06945"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch_geometric\n","  Downloading torch_geometric-2.6.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m640.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n","Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n","Downloading torch_geometric-2.6.0-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch_geometric\n","Successfully installed torch_geometric-2.6.0\n"]}],"source":["!pip install torch_geometric"]},{"cell_type":"code","source":["import random\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch_geometric.nn import GCNConv, DeepGraphInfomax\n","import torch\n","import torch_geometric\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.data import Data\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","import os"],"metadata":{"id":"D62kn7z7lD8E","executionInfo":{"status":"ok","timestamp":1726994816573,"user_tz":-180,"elapsed":351,"user":{"displayName":"Leonardo Daou","userId":"14703396650585608715"}}},"id":"D62kn7z7lD8E","execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":7,"id":"320ee17e","metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1726994779510,"user":{"displayName":"Leonardo Daou","userId":"14703396650585608715"},"user_tz":-180},"id":"320ee17e"},"outputs":[],"source":["class GCNNet(torch.nn.Module):\n","    def __init__(self, inp_dim, out_dim):\n","        super(GCNNet, self).__init__()\n","        self.conv1 = GCNConv(inp_dim, 32)\n","        self.conv2 = GCNConv(32, 64)\n","        self.conv3 = GCNConv(64, 128)\n","        self.conv4 = GCNConv(128, 128)\n","\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc = nn.Linear(128, out_dim)\n","\n","    def forward(self, x, edge_index, edge_attr):\n","        x = F.relu(self.conv1(x, edge_index, edge_attr))\n","        x = F.relu(self.conv2(x, edge_index, edge_attr))\n","        x = F.relu(self.conv3(x, edge_index, edge_attr))\n","        x = F.relu(self.conv4(x, edge_index, edge_attr))\n","\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        return x\n","\n","\n","class GraphClassifier:\n","    def __init__(self, inp_dim, out_dim, device):\n","        self.gcn = GCNNet(inp_dim, out_dim)\n","        self.gcn = self.gcn.to(device)\n","        self.optimizer = torch.optim.Adam(self.gcn.parameters())\n","\n","    def evaluate_loss(self, data, mode):\n","        # use masking for loss evaluation\n","        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n","        if mode == 'train':\n","            loss = F.cross_entropy(self.gcn(x, edge_index, edge_attr)[data.train_mask], data.y[data.train_mask])\n","        else:\n","            loss = F.cross_entropy(self.gcn(x, edge_index, edge_attr)[data.test_mask], data.y[data.test_mask])\n","        return loss\n","\n","    def embed(self, data):\n","        return self.gcn(data.x, data.edge_index, data.edge_attr)\n","\n","    def train(self, data):\n","        # training\n","        self.gcn.train()\n","        self.optimizer.zero_grad()\n","        loss = self.evaluate_loss(data, mode='train')\n","        loss.backward()\n","        self.optimizer.step()\n","        return loss.item()\n","\n","    def test(self, data):\n","        # testing\n","        self.gcn.eval()\n","        logits, accs = self.gcn(data.x, data.edge_index, data.edge_attr), []\n","        loss = self.evaluate_loss(data, mode='test').item()\n","\n","        for _, mask in data('train_mask', 'test_mask'):\n","            pred = logits[mask].max(1)[1]\n","            acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n","            accs.append(acc)\n","        return [loss] + accs\n","\n","\n","class DGIEncoderNet(torch.nn.Module):\n","    def __init__(self, inp_dim, out_dim):\n","        super(DGIEncoderNet, self).__init__()\n","        self.conv1 = GCNConv(inp_dim, 32)\n","        self.conv2 = GCNConv(32, 64)\n","        #self.conv3 = GCNConv(64, 128)\n","        #self.conv4 = GCNConv(128, 256)\n","        self.conv3 = GCNConv(64, out_dim)\n","\n","    def forward(self, x, edge_index, edge_attr, msk=None):\n","        x = F.elu(self.conv1(x, edge_index, edge_attr))\n","        x = F.elu(self.conv2(x, edge_index, edge_attr))\n","        #x = F.elu(self.conv3(x, edge_index, edge_attr))\n","        #x = F.elu(self.conv4(x, edge_index, edge_attr))\n","        x = self.conv3(x, edge_index, edge_attr)\n","        return x\n","\n","\n","class DGILearner:\n","    def __init__(self, inp_dim, out_dim, device):\n","        self.encoder = DGIEncoderNet(inp_dim, out_dim)\n","        self.dgi = DeepGraphInfomax(out_dim, encoder=self.encoder, summary=self.readout, corruption=self.corrupt)\n","        self.dgi = self.dgi.to(device)\n","\n","        self.optimizer = torch.optim.Adam(self.dgi.parameters())\n","\n","    def embed(self, data):\n","        pos_z, _, _ = self.dgi(data.x, data.edge_index, data.edge_attr, msk=None)\n","        return pos_z\n","\n","    def readout(self, z, x, edge_index, edge_attr, msk=None):\n","        if msk is None:\n","            return torch.sigmoid(torch.mean(z, 0))\n","        else:\n","            return torch.sigmoid(torch.sum(z[msk], 0) / torch.sum(msk))\n","\n","    def corrupt(self, x, edge_index, edge_attr, msk=None):\n","        shuffled_rows = torch.randperm(len(x))\n","        shuffled_x = x[shuffled_rows, :]\n","        return shuffled_x, edge_index, edge_attr\n","\n","    def evaluate_loss(self, data, mode):\n","        # use masking for loss evaluation\n","        pos_z_train, neg_z_train, summ_train = self.dgi(data.x, data.edge_index, data.edge_attr, msk=data.train_mask)\n","        pos_z_test, neg_z_test, summ_test = self.dgi(data.x, data.edge_index, data.edge_attr, msk=data.test_mask)\n","\n","        if mode == 'train':\n","            return self.dgi.loss(pos_z_train, neg_z_train, summ_train)\n","        else:\n","            return self.dgi.loss(pos_z_test, neg_z_test, summ_test)\n","\n","    def train(self, data):\n","        # training\n","        self.dgi.train()\n","        self.optimizer.zero_grad()\n","        loss = self.evaluate_loss(data, mode='train')\n","        loss.backward()\n","        self.optimizer.step()\n","        return loss.item()\n","\n","    def test(self, data):\n","        # testing\n","        self.dgi.eval()\n","        return self.evaluate_loss(data, mode='test').item()"]},{"cell_type":"code","execution_count":8,"id":"af61887a","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1726994779510,"user":{"displayName":"Leonardo Daou","userId":"14703396650585608715"},"user_tz":-180},"id":"af61887a"},"outputs":[],"source":["def train_model(dataset, train_mode, num_classes, device):\n","    if train_mode == 'supervised':\n","        model = GraphClassifier(dataset.num_node_features, num_classes, device)\n","    elif train_mode == 'unsupervised':\n","        model = DGILearner(dataset.num_node_features, 512, device)\n","    else:\n","        raise ValueError('Unsupported train mode {}'.format(train_mode))\n","    train_history=[]\n","    test_history=[]\n","    train_epochs = 81 if train_mode == 'supervised' else 1001\n","    for epoch in range(0, train_epochs):\n","        train_loss = model.train(dataset)\n","        if epoch % 5 == 0:\n","            if train_mode == 'unsupervised':\n","                log = 'Epoch: {:03d}, train_loss: {:.3f}, test_loss:{:.3f}'\n","                test_loss = model.test(dataset)\n","                print(log.format(epoch, train_loss, test_loss))\n","            else:\n","                log = 'Epoch: {:03d}, train_loss: {:.3f}, test_loss:{:.3f}, train_acc: {:.2f}, test_acc: {:.2f}'\n","                print(log.format(epoch, train_loss, *model.test(dataset)))\n","\n","    return model.embed(dataset).detach().cpu().numpy()"]},{"cell_type":"code","source":["name='Gavin'\n","newpath = r\"./\"+name"],"metadata":{"id":"tZp3FzQ25ZMg","executionInfo":{"status":"ok","timestamp":1726994779511,"user_tz":-180,"elapsed":14,"user":{"displayName":"Leonardo Daou","userId":"14703396650585608715"}}},"id":"tZp3FzQ25ZMg","execution_count":9,"outputs":[]},{"cell_type":"code","source":["newpath = r\"./\"+name+\"/Identity_Matrix/\"\n","newpath"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"DOGefU5F5rNK","executionInfo":{"status":"ok","timestamp":1726994779511,"user_tz":-180,"elapsed":14,"user":{"displayName":"Leonardo Daou","userId":"14703396650585608715"}},"outputId":"46f77a84-29f6-4fb1-f6a4-4ca825b89320"},"id":"DOGefU5F5rNK","execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'./Gavin/Identity_Matrix/'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","execution_count":13,"id":"yflErfxJxIsX","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"yflErfxJxIsX","executionInfo":{"status":"error","timestamp":1726994823290,"user_tz":-180,"elapsed":2787,"user":{"displayName":"Leonardo Daou","userId":"14703396650585608715"}},"outputId":"35dd95e1-5f30-4ea4-f14e-d0b5c0093699"},"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the name of the dataset: Gavin\n","Currently creating embedding for Gavin at timestep 1\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './Gavin/Identity_Matrix/GI1.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-f847b3659d05>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Currently creating embedding for\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"at timestep\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/Identity_Matrix/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Proteins'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Gavin/Identity_Matrix/GI1.csv'"]}],"source":["name=input(\"Enter the name of the dataset: \")\n","symbol=name[0]\n","timesteps=6\n","newpath = r\"./\"+name+\"/No_Feature/\"\n","if not os.path.exists(newpath):\n","    os.makedirs(newpath)\n","for l in range(0,timesteps):\n","  print(\"Currently creating embedding for\",name,\"at timestep\",l+1)\n","  s=\"./\"+name+\"/Identity_Matrix/\"+symbol+\"I\"+(str(l+1))+\".csv\"\n","  x=pd.read_csv(s)\n","  x.rename(columns={'Unnamed: 0': 'Proteins'}, inplace=True)\n","  x=x.set_axis(x.iloc[:,0], axis=0)\n","  del x[x.columns[0]]\n","  proteins=list(x.index)\n","  s=\"./\"+name+\"/Networks/\"+symbol+\"N\"+(str(l+1))+\".csv\"\n","  edge_index=pd.read_csv(s)\n","  edge_attr=list(edge_index.iloc[:,2])\n","  del edge_index[edge_index.columns[2]]\n","  for i in range(len(edge_index)):\n","    edge_index.iloc[i,0]=proteins.index(edge_index.iloc[i,0])\n","    edge_index.iloc[i,1]=proteins.index(edge_index.iloc[i,1])\n","  edge_index_c=edge_index.copy()\n","  edge_index_c.iloc[:,0]=edge_index.iloc[:,1]\n","  edge_index_c.iloc[:,1]=edge_index.iloc[:,0]\n","  edges=pd.concat([edge_index, edge_index_c], axis=0, ignore_index=True)\n","  edge_index=np.array(edges.transpose(),dtype=int)\n","  edge_attr.extend(edge_attr.copy())\n","  x = torch.tensor(np.array(x), dtype=torch.float)\n","  edge_index = torch.tensor(edge_index, dtype=torch.long)\n","  edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n","  train_mask=[True for i in range(round(len(proteins)*0.8))]\n","  train_mask.extend([False for i in range(round(len(proteins)*0.8),len(proteins))])\n","  train_mask=torch.tensor(train_mask,dtype=torch.bool)\n","  test_mask=[False for i in range(round(len(proteins)*0.8))]\n","  test_mask.extend([True for i in range(round(len(proteins)*0.8),len(proteins))])\n","  test_mask=torch.tensor(test_mask,dtype=torch.bool)\n","  data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr,train_mask=train_mask,test_mask=test_mask)\n","  data = data.to(device)\n","  embed = train_model(data, \"unsupervised\", 512, device)\n","  embedding=pd.DataFrame(embed)\n","  embedding=embedding.set_axis(proteins, axis=0)\n","  s=\"./\"+name+\"/No_Feature/\"+symbol+\"E\"+str(l+1)+\".csv\"\n","  embedding.to_csv(s)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}